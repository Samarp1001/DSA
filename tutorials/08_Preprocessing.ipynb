{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "yNdeTRZYvnfZ"
      },
      "source": [
        "# Preprocessing\n",
        "\n",
        "> This tutorial is based on Haystack 1.x. If you're using Haystack 2.0 and would like to follow the updated version of this tutorial, check out [Preprocessing Different File Types](https://haystack.deepset.ai/tutorials/30_file_type_preprocessing_index_pipeline).\n",
        ">\n",
        "> For more information on Haystack 2.0, read the [Haystack 2.0 announcement](https://haystack.deepset.ai/blog/haystack-2-release).\n",
        "\n",
        "Haystack includes a suite of tools to extract text from different file types, normalize white space\n",
        "and split text into smaller pieces to optimize retrieval.\n",
        "These data preprocessing steps can have a big impact on the systems performance and effective handling of data is key to getting the most out of Haystack."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "0xaAPp00vnff"
      },
      "source": [
        "Ultimately, Haystack expects data to be provided as a list of documents in the following dictionary format:\n",
        "``` python\n",
        "docs = [\n",
        "    {\n",
        "        'content': DOCUMENT_TEXT_HERE,\n",
        "        'meta': {'name': DOCUMENT_NAME, ...}\n",
        "    }, ...\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "d2_JHlh7vnfg"
      },
      "source": [
        "This tutorial will show you all the tools that Haystack provides to help you cast your data into this format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0iIqp30vnfh"
      },
      "source": [
        "## Installing Haystack\n",
        "\n",
        "To start, let's install the latest release of Haystack with `pip`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-lLMkltbvnfh",
        "outputId": "7bf3a77a-099a-4baa-f593-92ca7c688a73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.3.1)\n",
            "Requirement already satisfied: farm-haystack[colab,file-conversion,ocr,pdf,preprocessing] in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: boilerpy3 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (1.0.7)\n",
            "Requirement already satisfied: events in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (0.5)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (0.27.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (4.23.0)\n",
            "Requirement already satisfied: lazy-imports==0.3.1 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (0.3.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (10.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (3.4.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (2.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (9.0.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (4.3.6)\n",
            "Requirement already satisfied: posthog in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (3.7.0)\n",
            "Requirement already satisfied: prompthub-py==4.0.0 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (4.0.0)\n",
            "Requirement already satisfied: pydantic<2 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (1.10.19)\n",
            "Requirement already satisfied: quantulum3 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (0.9.2)\n",
            "Requirement already satisfied: rank-bm25 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (0.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (2.32.3)\n",
            "Requirement already satisfied: requests-cache<1.0.0 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (0.9.8)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (1.5.2)\n",
            "Requirement already satisfied: sseclient-py in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (1.8.0)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (9.0.0)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (0.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (4.66.6)\n",
            "Requirement already satisfied: transformers<5.0,>=4.46 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (4.46.2)\n",
            "Requirement already satisfied: pdf2image>1.14 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (1.17.0)\n",
            "Requirement already satisfied: pytesseract>0.3.7 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (0.3.13)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (1.0.9)\n",
            "Requirement already satisfied: nltk>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (3.9.1)\n",
            "Requirement already satisfied: azure-ai-formrecognizer>=3.2.0b2 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (3.3.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (4.12.3)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (3.7)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (1.1.2)\n",
            "Requirement already satisfied: python-frontmatter in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (1.1.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (0.4.27)\n",
            "Requirement already satisfied: python-pptx<=1.0 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (1.0.0)\n",
            "Requirement already satisfied: tika in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (2.6.0)\n",
            "Requirement already satisfied: pyyaml<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from prompthub-py==4.0.0->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (6.0.2)\n",
            "Requirement already satisfied: azure-core>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from azure-ai-formrecognizer>=3.2.0b2->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (1.32.0)\n",
            "Requirement already satisfied: msrest>=0.6.21 in /usr/local/lib/python3.10/dist-packages (from azure-ai-formrecognizer>=3.2.0b2->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (0.7.1)\n",
            "Requirement already satisfied: azure-common>=1.1 in /usr/local/lib/python3.10/dist-packages (from azure-ai-formrecognizer>=3.2.0b2->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (1.1.28)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from azure-ai-formrecognizer>=3.2.0b2->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (4.12.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.9.1->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.9.1->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.9.1->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (2024.9.11)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract>0.3.7->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (24.2)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from python-pptx<=1.0->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (3.2.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-pptx<=1.0->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (5.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (2024.8.30)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (1.4.4)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (24.2.0)\n",
            "Requirement already satisfied: cattrs>=22.2 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (24.1.2)\n",
            "Requirement already satisfied: url-normalize>=1.4 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (1.4.3)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<5.0,>=4.46->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0,>=4.46->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (0.26.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0,>=4.46->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0,>=4.46->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (0.20.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (2.6)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (0.14.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (0.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (2024.2)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (2.2.1)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from quantulum3->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (7.4.0)\n",
            "Requirement already satisfied: num2words in /usr/local/lib/python3.10/dist-packages (from quantulum3->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (0.5.13)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tika->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (75.1.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests-cache<1.0.0->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (1.2.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers<5.0,>=4.46->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (2024.10.0)\n",
            "Requirement already satisfied: isodate>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from msrest>=0.6.21->azure-ai-formrecognizer>=3.2.0b2->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (0.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from msrest>=0.6.21->azure-ai-formrecognizer>=3.2.0b2->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (1.3.1)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from inflect->quantulum3->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (4.4.1)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from num2words->quantulum3->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (0.6.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-ai-formrecognizer>=3.2.0b2->farm-haystack[colab,file-conversion,ocr,pdf,preprocessing]) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "pip install --upgrade pip\n",
        "pip install farm-haystack[colab,ocr,preprocessing,file-conversion,pdf]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QDzzDZpvnfk"
      },
      "source": [
        "### Enabling Telemetry\n",
        "Knowing you're using this tutorial helps us decide where to invest our efforts to build a better product but you can always opt out by commenting the following line. See [Telemetry](https://docs.haystack.deepset.ai/docs/telemetry) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ustERIGLvnfk"
      },
      "outputs": [],
      "source": [
        "from haystack.telemetry import tutorial_running\n",
        "\n",
        "tutorial_running(8)"
      ]
    },
    {
      "source": [
        "!pip install --upgrade pillow"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "U_4rNTFmwERF",
        "outputId": "d54d3093-48d0-4a67-989f-0aa823b14f79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.0.0)\n",
            "Collecting pillow\n",
            "  Downloading pillow-11.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Downloading pillow-11.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pillow\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.0.0\n",
            "    Uninstalling Pillow-9.0.0:\n",
            "      Successfully uninstalled Pillow-9.0.0\n",
            "Successfully installed pillow-11.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "dbcf0614a16c4fee9d24bbc171948da2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "G8Z25APBvnfl"
      },
      "source": [
        "## Logging\n",
        "\n",
        "We configure how logging messages should be displayed and which log level should be used before importing Haystack.\n",
        "Example log message:\n",
        "INFO - haystack.utils.preprocessing -  Converting data/tutorial1/218_Olenna_Tyrell.txt\n",
        "Default log level in basicConfig is WARNING so the explicit parameter is not necessary but can be changed easily:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Pe3ZwDwOvnfm"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
        "logging.getLogger(\"haystack\").setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "PAJzbMDnvnfm",
        "outputId": "71df3dd0-f7c2-44fe-da2b-403103bdeeff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.utils.import_utils:Found data stored in 'data/tutorial8'. Delete this first if you really want to fetch new data.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from haystack.utils import fetch_archive_from_http\n",
        "\n",
        "\n",
        "# This fetches some sample files to work with\n",
        "doc_dir = \"data/tutorial8\"\n",
        "s3_url = \"https://s3.eu-central-1.amazonaws.com/deepset.ai-farm-qa/datasets/documents/preprocessing_tutorial8.zip\"\n",
        "fetch_archive_from_http(url=s3_url, output_dir=doc_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "z9JzvhHnvnfm"
      },
      "source": [
        "## Converters\n",
        "\n",
        "Haystack's converter classes are designed to help you turn files on your computer into the documents\n",
        "that can be processed by the Haystack pipeline.\n",
        "There are file converters for txt, pdf, docx files as well as a converter that is powered by Apache Tika.\n",
        "The parameter `valid_languages` does not convert files to the target language, but checks if the conversion worked as expected. Here are some examples of how you would use file converters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qCfnsJEFvnfn"
      },
      "outputs": [],
      "source": [
        "from haystack.nodes import TextConverter, PDFToTextConverter, DocxToTextConverter, PreProcessor\n",
        "\n",
        "\n",
        "converter = TextConverter(remove_numeric_tables=True, valid_languages=[\"en\"])\n",
        "doc_txt = converter.convert(file_path=\"data/tutorial8/classics.txt\", meta=None)[0]\n",
        "\n",
        "converter = PDFToTextConverter(remove_numeric_tables=True, valid_languages=[\"en\"])\n",
        "doc_pdf = converter.convert(file_path=\"data/tutorial8/bert.pdf\", meta=None)[0]\n",
        "\n",
        "converter = DocxToTextConverter(remove_numeric_tables=False, valid_languages=[\"en\"])\n",
        "doc_docx = converter.convert(file_path=\"data/tutorial8/heavy_metal.docx\", meta=None)[0]"
      ]
    },
    {
      "source": [
        "!apt-get install -qq poppler-utils"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "UTcuiSeswZdB",
        "outputId": "0afe9672-80ef-44cf-c9e1-ad93ebe94d5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 123629 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.5_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.5) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.5) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWRj82Wdvnfn"
      },
      "source": [
        "Haystack also has a convenience function that will automatically apply the right converter to each file in a directory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "cMy-ZazWvnfn",
        "outputId": "b61a36f2-e9d8-47ed-ad18-162ff795697c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.utils.preprocessing:Converting data/tutorial8/classics.txt\n",
            "INFO:haystack.utils.preprocessing:Converting data/tutorial8/bert.pdf\n",
            "INFO:haystack.utils.preprocessing:Converting data/tutorial8/heavy_metal.docx\n"
          ]
        }
      ],
      "source": [
        "from haystack.utils import convert_files_to_docs\n",
        "\n",
        "\n",
        "all_docs = convert_files_to_docs(dir_path=doc_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "5EWPrE0Zvnfo"
      },
      "source": [
        "## PreProcessor\n",
        "\n",
        "The PreProcessor class is designed to help you clean text and split text into sensible units.\n",
        "File splitting can have a very significant impact on the system's performance and is absolutely mandatory for Dense Passage Retrieval models.\n",
        "In general, we recommend you split the text from your files into small documents of around 100 words for dense retrieval methods\n",
        "and no more than 10,000 words for sparse methods.\n",
        "Have a look at the [Preprocessing](https://docs.haystack.deepset.ai/docs/preprocessor)\n",
        "and [Optimization](https://docs.haystack.deepset.ai/docs/optimization) pages on our website for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "zW_keTwmvnfo",
        "outputId": "14998de4-fb0b-4236-bef9-a58a1a83d2d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "Preprocessing: 100%|██████████| 1/1 [00:00<00:00, 22.28docs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_docs_input: 1\n",
            "n_docs_output: 51\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from haystack.nodes import PreProcessor\n",
        "\n",
        "\n",
        "# This is a default usage of the PreProcessor.\n",
        "# Here, it performs cleaning of consecutive whitespaces\n",
        "# and splits a single large document into smaller documents.\n",
        "# Each document is up to 1000 words long and document breaks cannot fall in the middle of sentences\n",
        "# Note how the single document passed into the document gets split into 5 smaller documents\n",
        "\n",
        "preprocessor = PreProcessor(\n",
        "    clean_empty_lines=True,\n",
        "    clean_whitespace=True,\n",
        "    clean_header_footer=False,\n",
        "    split_by=\"word\",\n",
        "    split_length=100,\n",
        "    split_respect_sentence_boundary=True,\n",
        ")\n",
        "docs_default = preprocessor.process([doc_txt])\n",
        "print(f\"n_docs_input: 1\\nn_docs_output: {len(docs_default)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "iWIPRM3Mvnfo"
      },
      "source": [
        "## Cleaning\n",
        "\n",
        "- `clean_empty_lines` will normalize 3 or more consecutive empty lines to be just a two empty lines\n",
        "- `clean_whitespace` will remove any whitespace at the beginning or end of each line in the text\n",
        "- `clean_header_footer` will remove any long header or footer texts that are repeated on each page"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "jNH8gzqYvnfo"
      },
      "source": [
        "## Splitting\n",
        "By default, the PreProcessor will respect sentence boundaries, meaning that documents will not start or end\n",
        "midway through a sentence.\n",
        "This will help reduce the possibility of answer phrases being split between two documents.\n",
        "This feature can be turned off by setting `split_respect_sentence_boundary=False`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "xDLAlQ8kvnfo",
        "outputId": "42356152-bbfa-4b16-cde9-725ef21cfced",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "Preprocessing: 100%|██████████| 1/1 [00:00<00:00, 86.94docs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESPECTING SENTENCE BOUNDARY\n",
            "End of document: \"...rnerstone of a typical elite European education.\n",
            "\n",
            "\"\n",
            "\n",
            "NOT RESPECTING SENTENCE BOUNDARY\n",
            "End of document: \"...xts used as part of a curriculum, both derive from\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Not respecting sentence boundary vs respecting sentence boundary\n",
        "\n",
        "preprocessor_nrsb = PreProcessor(split_respect_sentence_boundary=False)\n",
        "docs_nrsb = preprocessor_nrsb.process([doc_txt])\n",
        "\n",
        "print(\"RESPECTING SENTENCE BOUNDARY\")\n",
        "end_text = docs_default[0].content[-50:]\n",
        "print('End of document: \"...' + end_text + '\"')\n",
        "print()\n",
        "print(\"NOT RESPECTING SENTENCE BOUNDARY\")\n",
        "end_text_nrsb = docs_nrsb[0].content[-50:]\n",
        "print('End of document: \"...' + end_text_nrsb + '\"')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "O6UK7ouhvnfp"
      },
      "source": [
        "A commonly used strategy to split long documents, especially in the field of Question Answering,\n",
        "is the sliding window approach. If `split_length=10` and `split_overlap=3`, your documents will look like this:\n",
        "\n",
        "- doc1 = words[0:10]\n",
        "- doc2 = words[7:17]\n",
        "- doc3 = words[14:24]\n",
        "- ...\n",
        "\n",
        "You can use this strategy by following the code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "QVacQJ_vvnfp",
        "outputId": "9bfac8b7-b922-492f-f18e-5454d37cb4da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "Preprocessing: 100%|██████████| 1/1 [00:00<00:00, 21.91docs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 1: \"Classics or classical studies is the study of classical antiquity,...\"\n",
            "Document 2: \"of classical antiquity, and in the Western world traditionally refers...\"\n",
            "Document 3: \"world traditionally refers to the study of Classical Greek and...\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Sliding window approach\n",
        "\n",
        "preprocessor_sliding_window = PreProcessor(split_overlap=3, split_length=10, split_respect_sentence_boundary=False)\n",
        "docs_sliding_window = preprocessor_sliding_window.process([doc_txt])\n",
        "\n",
        "doc1 = docs_sliding_window[0].content[:200]\n",
        "doc2 = docs_sliding_window[1].content[:100]\n",
        "doc3 = docs_sliding_window[2].content[:100]\n",
        "\n",
        "print('Document 1: \"' + doc1 + '...\"')\n",
        "print('Document 2: \"' + doc2 + '...\"')\n",
        "print('Document 3: \"' + doc3 + '...\"')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "T5FwHWADvnfp"
      },
      "source": [
        "## Bringing it all together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "oB2bJjTtvnfp",
        "outputId": "df10d8d9-25cf-4fb9-bcb7-3e3d5d28e52a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.utils.preprocessing:Converting data/tutorial8/classics.txt\n",
            "INFO:haystack.utils.preprocessing:Converting data/tutorial8/bert.pdf\n",
            "INFO:haystack.utils.preprocessing:Converting data/tutorial8/heavy_metal.docx\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "Preprocessing:   0%|          | 0/3 [00:00<?, ?docs/s]WARNING:haystack.nodes.preprocessor.preprocessor:We found one or more sentences whose split count is higher than the split length.\n",
            "Preprocessing: 100%|██████████| 3/3 [00:00<00:00, 13.09docs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_files_input: 3\n",
            "n_docs_output: 175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "all_docs = convert_files_to_docs(dir_path=doc_dir)\n",
        "preprocessor = PreProcessor(\n",
        "    clean_empty_lines=True,\n",
        "    clean_whitespace=True,\n",
        "    clean_header_footer=False,\n",
        "    split_by=\"word\",\n",
        "    split_length=100,\n",
        "    split_respect_sentence_boundary=True,\n",
        ")\n",
        "docs = preprocessor.process(all_docs)\n",
        "\n",
        "print(f\"n_files_input: {len(all_docs)}\\nn_docs_output: {len(docs)}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "bda33b16be7e844498c7c2d368d72665b4f1d165582b9547ed22a0249a29ca2e"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}